<h1 id="methodology">Methodology</h1>
<h2 id="solution-architecture">Solution architecture</h2>
<p>The number of implementations of DAO’s is going to be exponentially growing and there is a need for level-1 blockchain protocols to be able to deal with the increased volume of transactions and history where pruning is going to be needed. A blockchain is in essence a ledger of immutable records, which need to be combined to form an end ‘world state’. In order to obtain this world state, history needs to be kept as from genesis of the blockchain.</p>
<p>Increase in volume and transactions creates issues at some point in time, with a ledger that becomes too big for a decent synchronisation.</p>
<p>From the literature research we formed ideas how we can come to a “non intrusive” pruning system for regular blockchain protocols without necessarily make major changes to the existing blockchain and consensus algorithms. To form such a solution there are a number of technology components that will make creating such a solution possible or easier to create.</p>
<h3 id="necessary-conditions.">Necessary conditions.</h3>
<p>Blockchains enable organizations to run decentralized, they allow value transaction to be done without a third party in the middle and any other use case of blockchain technology always revolves around decentralization. The permissionless blockchain provide the most pure form of decentralization where node owners and operators decide for themselves whether the reward for operating a node is sufficient for then to get involved or not. Permissioned blockchains have a slightly less z character but certainly a distributed character where the reward is not just governed by an algorithm because here there might be a legal entity involved to orchestrate the rewards system. This legal entity might be a DAO (Distributed Autonomous Organization).</p>
<p>To honor this z aspect the of node storage facility cannot be governed or owned by one (or a few) legal entities, it was to follow the same principle of permissionless or permissioned with a DAO. In order to create an architecture that can store historical blockchain data and allow the blockchain nodes to have a portion local to the node and the largest part of the history of the chain in a remote storage facility (pruning) and keep inline with z character of blockchains in general we see the following key technical necessary conditions:</p>
<p><strong>Necessary condition 1</strong>. <em>Secure, autonomous, decentralized and distributed data processing and storage utility</em></p>
<p>To create autonomous, z and distributed data processing and storage utility we need an operating system that provides maximum security by not allowing people to give it instructions or interact with it. To reach a distributed and decentralized grid os processing and storage capacity we cannot rely on people to install and operate standard operating systems. A standard operating system would allow te individual owners of these nodes to be able to see (and potentially manipulate) the incoming data parts to be stored.</p>
<p>There is technology being build that that gets its instructions from a z ledger and a smart contract that governs the execution of these instructions. Such an operating system would allow the compute and storage nodes involved in the pruning solution to be safe, private, sovereign and autonomous in it’s operations.</p>
<p><strong>Necessary condition 2</strong>. <em>Immutable and always-append storage device</em></p>
<p>Use a low level storage device that uses a physical storage in such a way like a blockchain: always append and immutable. So when data is committed to this storage device it cannot be deleted. The data is committed and stored on this storage device for as long as this device is part of the storage system for pruned data.</p>
<p><strong>Necessary condition 3</strong>. <em>Encrypted secure networking</em></p>
<!--  (maybe to be deleted, as there's not really data to secure when pruning) -->
<p>Use secure and encrypted networking between the blockchain nodes and the storage utility. Chain data needs to be transported off node and we need to have certainty that data cannot be changed or messed with in the transport part of the pruning process. Therefore encrypted networking is an important component for taking chain data off blockchain nodes the the storage facility</p>
<p><strong>Necessary condition 4</strong>. <em>Filesystem that presents remote storage to blockchain node</em></p>
<p>Minimal to no impact to the blockchain nodes, the off-node storage utility should be presenting itself on the blockchain node as a normal filesystem. All activities of storing data away from the blockchain node, creating the necessary proof points along the way for: - authenticity of being pruned from this node - comparing off chain data from different nodes to contain the same data - de-duplicating data<br />
- other activities to condense the data footprint and make the whole blockchain more efficient and scalable</p>
<p>Some blockchain protocols have built in capabilities that allow partial backup of chain data and provide the required proof of the authenticity of the partial backup which makes the remote storage filesystem an ideal way to take data off-node.</p>
<p><strong>Necessary condition 5</strong>. <em>Secure access to remote stored and de-duplicated data</em></p>
<p>Provide secure access to the stored history of the chains and make all nodes (ideally) use de-duplicated copies of the historic data.</p>
<p>With these elements we should be able to build a secure off node storage space for all nodes and then devise a method to check the integrity of all stored chain data and deduplicate it to a degree to have less copies stored forever.</p>
<h2 id="solution-components">Solution components</h2>
<p>To fullfil the necessary conditions mentioned earlier there are a number of components in the ThreeFold technology stack that meet the condition. Here is a brief description of how components meet the conditions.</p>
<h3 id="secure-and-autonomous-operating-system">Secure and autonomous Operating System</h3>
<p>The principles to build a secure and autonomous operating system to build a z and distributed grid of capacity are as follows:</p>
<ul>
<li><em>Autonomy</em>: to create compute, storage and networking capacity everywhere you can not rely on a remote (or a local) maintainer of the operating system. Also owners should not have to be operating system administrators. By making the OS autonomous and not allowing owners or systems administrators to log in to the OS you make it a very secure operating system.</li>
<li><em>Simplicity</em>: An operating system should be simple, able to exist anywhere, for anyone, good for the planet. Simplicity also enhances the overall security of a system</li>
<li><em>Stateless</em>: In a grid (Peer To Peer) set up, the sum of the components is providing a stable basis for single elements to fail and not bring the whole system down. Therefore, it is necessary for single elements to be stateless, and the state needs to be stored within the grid.</li>
</ul>
<p><img src="./img/threefold__zero_os_overview.jpg" alt="threefold_zero_os_overview" width="800"/></p>
<p>Building an autonomous, simple and stateless OS is not an easy feat. Not having access means that is has to be 100% right at time of deployment. Zero-OS has been developed and improved over the last 5 years and is now ready to be the capacity generator for secure IT workloads where compute, storage and networking components interact.</p>
<h3 id="immutable-and-always-append-storage-protocol">Immutable and always-append storage protocol</h3>
<p>In such a autonomous operating system storing data can be done in a very secure manner. As owners, administrators and users to not have direct access to the operating system a very secure environment is created to run applications and store data. Also since this operating system is made to form a grid creating ubiquitous compute, storage and network utility local storage devices can be used to make a “dispersed” storage system.</p>
<p>At the foundation of such a dispersed storage system sits a zero-DB. Zero-db is a fast and efficient key-value store (redis-protocol compatible), which makes data persistent inside an always append data file, with namespaces support. This zero-DB is able to receive and send information over the secure network that spans between all the zero-OS’s and as such many zero-DB’s can together create a large storage lake.</p>
<p>The Zero-DB stores data like a key-value store, and can operate (when configured to do so) to store data sequentially which makes it an “always append” storage device. For caching purposes it can also be configured to not do this.</p>
<p><img src="./img/threefold__zdb_arch.jpg" alt="threefold_zdb_arch" width="800"/></p>
<h3 id="encrypted-secure-networking-the-planetary-network">Encrypted secure networking: the Planetary Network</h3>
<p>The planetary network is an overlay network which lives on top of the existing internet (or any other network created). In this network, everyone is connected to everyone. End-to-end encryption between users of an app the zero-OS’s these applications run on.</p>
<p>Each user and network point is strongly authenticated and uniquely identified, independent of the network carrier used. There is no need for a centralized firewall or VPN solutions, as there is a circle based networking security in place.</p>
<p>Benefits : - shortest possible paths between peers, independent of the network providers routing decisions - end-to-end encrypted data transport create full security - peer2peer links like meshed wireless - broken internet links do not affect the operating of traffic by re-routing traffic when needed</p>
<p><img src="./img/threefold__planet_net_.jpg" alt="panetary_network" width="800"/></p>
<h3 id="filesystem-that-present-remote-storage-to-blockchain-node">Filesystem that present remote storage to blockchain node</h3>
<p>Quantum Safe Storage System uses a dispersed storage algorithm to distribute the data in a smart way and stores data in different locations. The original object is fragmented, compressed and encrypted, and than a “description” is created of that compressed and encrypted data part which is stored. The original compressed and encrypted data is deleted. Only that description of that data part of the information is stored, making it impossible to understand what data(part) is stored on a single device as you need all the descriptions together to be able to “un-describe” the compressed and encrypted original data</p>
<p>The data is described in a way such that a person aiming to hack into the low-level data (which is almost impossible in itself), will only find non-relevant information on this storage infrastructure and the other data shards can’t be re-created, making it quantum-proof.</p>
<p>Quantum Safe Storage System offers the following storage benefits:</p>
<ul>
<li>Store Petabytes of data at hyper-competitive pricing.</li>
<li>Quantum-safe security (not even a quantum computer can hack).</li>
<li>A filesystem interface see Quantum Safe Filesystem</li>
<li>Unlimited scalability provided by the ThreeFold P2P infrastructure.</li>
<li>Self-healing capability of the storage layer ensures your data remains available at all times.</li>
</ul>
<p><img src="./img/threefold__zos_zstor.jpg" alt="zos_zero_store" width="800"/></p>
<h3 id="secure-access-to-de-duplicated-data">Secure access to de-duplicated data</h3>
<p>…</p>
<p>ThreeFold Tech has developed the technology to store immutable records in a more space efficient way, relying on a fully z grid of storage capacity. No participant has the full storage volume on his hard drive, however the combination of all participants allows recomposing of the full ledger with all records. This method brings many benefits: - The storage happens in a very, quantum-resilient way, as attacking one chunk gives insufficient information to recreate the authentic data; - Storage grows slower over time compared to a classic blockchain setup, as storage overhead can be limited to about 20% instead of the ‘traditional’ 10000% (in the case of 100 participants running a blockchain node) overhead; - It allows for an easy way to implement pruning: only the current state is really required to be stored locally, and when transactions come in, a recalculation is made, and the storing of the historical transactions is directly done using QSFS</p>
<h2 id="proposed-solution-directions-methods-to-architect-a-pruning-solution">Proposed solution directions methods to architect a pruning solution</h2>
<h3 id="introduction">Introduction</h3>
<p>For many blockchain nodes every (full / validator) node that partakes in the blockchain operation run the layer-1 blockchain software which is part of the blockchain operations. At this point in time we leave the complexities out that come with the the blockchain being permissionless or permissioned. This has major impact on how nodes build trust between themselves and the resulting consensus mechanism that operates the blockchain protocol. For this part of the research we are going to focus on how these blockchain nodes store that data after consensus and trust has been build between all participating nodes.</p>
<h3 id="method-1-use-traditional-full-and-incremental-backup-principles-to-backup-a-database.">Method 1: use traditional full and incremental backup principles to backup a database.</h3>
<p>Any blockchain node uses local available disk drives to write its full chain data and chain state to. For some (layer-1) protocols a database is used (like <a href="https://github.com/LMDB/bitmonero">Monero</a>) and for others other data formats have been chosen. These formats might be databases, key values stores or other means of putting data in a structured format before committing it to disk.</p>
<p>Popular cryptocurrencies use a mix of LevelDB and BerkeleyDB. High-performance blockchain databases such as BigchainDB and ProvenDB are using MongoDB. So each blockchain node runs a local database of sort to store its local chain data and indexes it in a certain way to make it searchable and fast responding to queries.</p>
<p><img src="../img/blockchain_local_operation.svg" alt="blockchain_pruning_option_1" width="800"/></p>
<p>In such a setup one can look at database specific export or backup features to partial exports and backups to store a part af the chain data off-node.</p>
<h3 id="method-2-install-and-use-additional-software-on-the-node-to-prune-chain-data">Method 2: Install and use additional software on the node to prune chain data</h3>
<p><img src="../img/pruning_block_write_option_1.svg" alt="blockchain pruning option 1" width="800"/></p>
<h3 id="method-3-use-an-external-decentralized-storage-facility-and-uses-chain-consensus">Method 3: Use an external (decentralized storage facility and uses chain consensus)</h3>
<p><img src="../img/pruning_block_write_option_2.svg" alt="blockchain pruning option 2" width="800"/></p>
<!--
## Process

### Step 1 : Consensus

The first step in the consensus protocol does not change: n nodes agree on validity of blocks. Once consensus is achieved (using whatever consensus protocol like PoS, PoW, ...) records are stored and de-duplicated over all n nodes. 
With one difference, however, which is that the transactions are stored in a Z-Stor dedupe format, over p storage nodes + q redundant ones (typically 20% of overhead) in a Zero-DB format. 

### Step 2 : Fill block batch

We propose to group a number of blocks, either for an agreed number of blocks. Idea is to come to a sufficient volume to put aside (ex. 30 MB), and keep the transactional history on-chain as long as the agreed block number hasn't been reached. During this period, history is collected in n*(p+q) equal chunks of data.  

### Step 3 : Batch closing 

Once the agreed block number has been fully completed (= consensus achieved), the chunks are closed and are ready to be put off-chain. The zstor format ensures that data is immutable, a fingerprint is created and linking information to where the chunks can be found. This information is registered on-chain. 

### Step 4 : Off-chain storage follow-up

A few challenges arise with this setup :
- Data rot can happen, a node can disconnect or other events can happen making that a node starts behaving as a bad actor. 
- Every time a batch is closed, the metadata describing the location of the historic batches also go off-chain. 

Both elements require an active follow-up of where historic batches of transactions are to be found is needed. 
This is why the following is proposed:
- Within each new storage batch process, a process is launched to register the location of historic batches on the new active part of the chain. 
- Over time, a number of batches are created. Let's call the number of completed batches `y`. 
- An election needs to happen of `y * (p + q)` chunks. During this election, nodes propose the storing of a chunk, with a number of rules: 
  - The number of eligible chunks per batch per node is less than q (and preferably 1), in order to guarantee that the information is decentralized enough to ensure continuity of service in case a node gets disconnected. 
  - A batch can't be closed as long as the election process for each of the `y * (p + q)` hasn't been completed. 
  - An election process is triggered by 'candidates', launching a 'proof of storage' transaction, indicating the location of the chunk and a fingerprint of the data including recent info (nonce, timestamp, ... ) and proof of authenticity. The election process for a history batch is completed once `p + q` transactions are selected. 
- For older chunks, re-election in every new active batch is possible. However, a chunk storage holder should present his 'proof of storage' in every new batch. 
- In a permissioned model, the election of new chunk holders is part of the authority rights, and no incentive is to be foreseen. For permissionless models, an incentivization mechanism needs to be worked out for every new election. 

#### How to split up the data chunks when a batch has just been completed ? 

At batch completion, there are logically n*(p+q) chunks available. However, this completed batch can't be pruned until the completion of the next batch, during which election happens of p+q 'historic chunk batch holders'. 
Number of chunks for every election needed is p+q, with p and q natural numbers and p>1, q>0. q=0 is not viable, as data rot might occur, so the idea is that there is always an objective to keep p+q chunks available, and when a chunks gets unreachable, a new chunk is being created.

The intention is to have (p+q) chunks available at any moment in time, for each batch, hence the re-election of every chunk for every new batch. The keeping of 1 or more of these chunks can be incorporated into the validator node code, but will require way less storage volume than the current full nodes. Moreover the storage can be kept off-chain, as an 'active' transaction archive. 

#### How to recollect the pieces if a historical transaction is to be recovered ? 

- In every of the y completed storage batches, all info is available as a transaction to recover y * (p + q) chunks, and with this info the full transaction history can be recovered, using y * p chunks and y * q spare ones. 

### 1. remote mounted secure filesystem

- mount remote qsfs filesystem on the blockchain node and use the mount to store all blockchain data.  
- mounted filesystem uses external data processor takes the data and stores it "quantum safe".  
- data processor fragments, compresses and encrypts the data and then uses these data fragments to build a mathematical description of the data.  mathematical description is stored, data is discarded
- generate proof that this mathematical description is linked to the original data
- generate proof that the original data from this node is identical to other nodes data
- store both (and/or more) proofs in the same manner (fragment, compress and encrypt with what a mathematical description is created of the data)

### 2. local storage store blockchain data and process take data and sends it to remote store

- blockchain node uses local storage to store chain data.
- process running on the local node takes the stored data and send it to a remote (secure) location for storage periodically (hourly, daily, weekly).
- data processor fragments, compresses and encrypts the data and then uses these data fragments to build a mathematical description of the data.  mathematical description is stored, data is discarded.  Zero proof storage system.
- remote (distributed) storage facility has all copies of all nodes data and an external verifier verifies that all data is the same (pruning validator, could be consensus, permissionless oriented).
- verifiers verify that all the data collected on the distributed storage facility are the same and create proof for it.
- process terminates 95% of the data stored and keeps 5% of the data copies and stores the proof that all the copies dis have the same data.
-->
